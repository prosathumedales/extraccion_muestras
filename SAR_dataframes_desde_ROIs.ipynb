{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qJ2W3QX6DVNV"
   },
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "from osgeo import gdal, ogr\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YOFOWzBOdrXm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mask_from_vector_per_polygon(vector_data_path, cols, rows, geo_transform,\n",
    "                            projection, attribute = 'id', all_touched= False, nodatavalue=-9999):\n",
    "    #\"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\" # Funcion obtenida de internet y modififcada\n",
    "    \"\"\" Rasteriza una capa vectorial\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector_data_path: str\n",
    "      Direccion del archivo del shapefile\n",
    "    cols: int\n",
    "      Cantidad de columnas deseadas para el raster\n",
    "    rows: int\n",
    "     Cantidad de filas deseadas para el raster\n",
    "    geo_transform: \n",
    "      \n",
    "    projection:\n",
    "    \n",
    "    attribute: str\n",
    "      Nombre de la columna del shapefile que se utilizará para identificar a los polígonos\n",
    "    all_touched: bool\n",
    "      Si es True, se consideraran todos los pixeles que intersecan con los polígono. Si es False, solo se consideraran aquellos pixeles que caen dentro del poligono.\n",
    "    nodatavalue=-9999\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        un array que tendra valores 0 en aquellos lugares donde no haya poligonos y valores del attribute para cada poligono.\n",
    "    \"\"\"\n",
    "\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    layer = data_source.GetLayer(0)\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')  # In memory dataset\n",
    "    target_ds = driver.Create('target.tif', cols, rows, 1, gdal.GDT_Float32)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(nodatavalue)\n",
    "\n",
    "    if all_touched ==True:\n",
    "    \tgdal.RasterizeLayer(target_ds, [1], layer, options=[\"ATTRIBUTE=\"+attribute, \"ALL_TOUCHED= TRUE\"])\n",
    "    else:\n",
    "    \tgdal.RasterizeLayer(target_ds, [1], layer, options=[\"ATTRIBUTE=\"+attribute])\n",
    "    return target_ds.ReadAsArray()\n",
    "\n",
    "\n",
    "def get_saocom_date(src_xemt_file):\n",
    "  \"\"\" Dado un arhivo xemt, obtiene la fecha de adquisicion\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_xemt_file : str\n",
    "        Direccion al archivo xemt\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Fecha de adquisicion en formato:\n",
    "  \"\"\"\n",
    "\n",
    "  tree = ET.parse(src_xemt_file)\n",
    "  root = tree.getroot()\n",
    "  s =ET.tostring(root, encoding='utf8').decode('utf8')\n",
    "  substring_acq = s[s.find('<acquisitionTime>'):s.find('</acquisitionTime>')]\n",
    "  n =substring_acq.find('<startTime>')\n",
    "  return substring_acq[n+11:n+21]\n",
    "\n",
    "def get_date(raster_name_src, sensor, alos_dates_csv = '/media/nmorandeira/T7/Img_preprocesadas/Raster/SAR/ALOS/asf-datapool-index.csv', saocom_dates_xmet=''):\n",
    "  \"\"\" Para cada sensor (ALOS, SENTINEL1, SAOCOM) obtiene un string que representa las fechas de adquisicion de la imagen\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster_name_src : str\n",
    "        Direccion al archivo raster de la imagen\n",
    "    sensor: str\n",
    "        Detalle del sensor. Opciones: ALOS, SENTINEL1, SAOCOM\n",
    "    alos_dates_csv: str\n",
    "        Direccion al csv que contiene las fechas de las imagenes\n",
    "    saocom_dates_xmet: str\n",
    "        Direccion al xmet que contiene las fecha de la imagene\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Fecha de adquisicion en formato:\n",
    "  \"\"\"\n",
    "  if sensor == 'SENTINEL':\n",
    "    result = re.search('1SDV_(.*)', raster_name_src)\n",
    "    result = datetime.strptime(result.group(1)[:8], '%Y%m%d').strftime('%Y-%m-%d')#.strftime('%d/%m/%Y')\n",
    "  elif sensor== 'ALOS':\n",
    "    n = raster_name_src.find('ALPSRP')\n",
    "    id_img_name = raster_name_src[n:n+15]\n",
    "    df_alos_dates = pd.read_csv(alos_dates_csv)\n",
    "    result = df_alos_dates[df_alos_dates['Granule Name']==id_img_name]['Acquisition Date'].values[0][:10]\n",
    "  elif sensor== 'SAOCOM':\n",
    "    result = get_saocom_date(saocom_dates_xmet)\n",
    "  return result\n",
    "\n",
    "\n",
    "def vector_table_to_dic(shp_file, replace_spaces_in_strings = True):\n",
    "  \"\"\"Crea un diccionario a partir de los valores de la tabla del shapefile\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  shp_file : str\n",
    "      Direccion al archivo shapefile\n",
    "  replace_spaces_in_strings : bool, optional\n",
    "      Si es True, reemplaza los espacios que aparecen en la tabla por \"_\"\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      Diccionario\n",
    "  \"\"\"\n",
    "  \n",
    "  dataSource = ogr.Open(shp_file) #abrir el shapefile como objeto espacial\n",
    "  daLayer = dataSource.GetLayer(0) #obtener el primer ítem del objeto espacial\n",
    "  layerDefinition = daLayer.GetLayerDefn() #obtener info de campos\n",
    "  l = []\n",
    "  for i in range(layerDefinition.GetFieldCount()):\n",
    "      l.append(layerDefinition.GetFieldDefn(i).GetName())\n",
    "  d = {}\n",
    "  i = 0\n",
    "  for feature in daLayer:\n",
    "    d[i] = {}\n",
    "    for field in l:\n",
    "      d[i][field] = feature.GetField(field)\n",
    "      #print(field, feature.GetField(field))\n",
    "    i = i+1\n",
    "\n",
    "  if replace_spaces_in_strings:\n",
    "    for k in d.keys():\n",
    "      for j in d[k].keys():\n",
    "        if type(d[k][j])==str:\n",
    "          d[k][j]=d[k][j].replace(' ', '_')\n",
    "  return d\n",
    "\n",
    "def add_table_values_to_df(d,df):\n",
    "  \"\"\"Pasa los datos contenidos en un diccionario d a un pd.DataFrame df\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : dict\n",
    "\n",
    "    df : pd.DataFrame\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        \n",
    "  \"\"\"\n",
    "  ids = [int(d[k]['id']) for k in d.keys()]\n",
    "  for i in ids:\n",
    "    values = [k for k in d.keys() if d[k]['id']==i]\n",
    "    d_ = d[values[0]]\n",
    "    for k in d_.keys():\n",
    "      df.loc[df['id'] == i, k] = d_[k]\n",
    "  return df\n",
    "\n",
    "def get_bands_information(src):\n",
    "  \"\"\"Obtiene el level de imagen, la canidad de bandas y los nombres de cada una de ellas.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        Direccion al archivo (bandas.txt) que contiene la informacion de las bandas de la imagen\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    level\n",
    "        un string que representa el level de la imagen\n",
    "    n_bandas\n",
    "        un int que representa la cantidad de bandas que contiene la imagen\n",
    "    bandas_nombres\n",
    "        una lista que contiene los nombres de las bandas (str) de manera ordenada\n",
    "  \"\"\"\n",
    "  with open(src) as f:\n",
    "    lines = f.readlines()\n",
    "  level = lines[0].replace('\\n',\"\")\n",
    "  n_bandas = len(lines)-1\n",
    "  bandas_nombres = []\n",
    "  for v in range(1,n_bandas+1):\n",
    "    bandas_nombres.append(lines[v].replace('\\n',\"\"))\n",
    "  \n",
    "  return level, n_bandas, bandas_nombres\n",
    "\n",
    "def get_mean_std_values_from_img(img_complete, shp_file, n_bandas, bandas_nombres):\n",
    "  img_test = gdal.Open(img_complete,gdal.GA_ReadOnly)\n",
    "  img_test_arr = img_test.ReadAsArray()\n",
    "  #print(img_test_arr.shape)\n",
    "\n",
    "  rows, cols = img_test_arr.shape[1:]\n",
    "  geo_transform = img_test.GetGeoTransform()\n",
    "  projection = img_test.GetProjection()\n",
    "\n",
    "  target = create_mask_from_vector_per_polygon(shp_file, cols, rows, geo_transform, projection, attribute = 'id', all_touched= False)\n",
    "  a, c = np.unique(target, return_counts = True)\n",
    "  d = {}\n",
    "  nodatavalue=-9999\n",
    "  a = [i for i in a if i!=nodatavalue]\n",
    "\n",
    "  for i in a:\n",
    "    mask = target == i\n",
    "    np.unique(mask, return_counts=True)\n",
    "    masked = img_test_arr[:,mask[:,:]]\n",
    "    if n_bandas>1:\n",
    "      means = np.mean(masked, axis=1)\n",
    "      stds = np.std(masked, axis=1)\n",
    "    d_aux = {}\n",
    "\n",
    "    incidence_angle_band = np.where(np.array(bandas_nombres)=='incidence_angle' )[0][0]\n",
    "    incidence_angle_mean = means[incidence_angle_band]\n",
    "\n",
    "    d_calculated = {}\n",
    "    \n",
    "    if np.where(np.array(bandas_nombres)=='HV2')[0].shape[0]!=0:\n",
    "      hv2_band_num = np.where(np.array(bandas_nombres)=='HV2')[0][0]\n",
    "      d_calculated['HV'] = img_test_arr[hv2_band_num,:,:]/2\n",
    "\n",
    "    if sum([i.find('C13')!=-1 for i in bandas_nombres])==2:\n",
    "      c13real_band_num = np.where(np.array(bandas_nombres)=='C13_real')[0][0]\n",
    "      c13imag_band_num = np.where(np.array(bandas_nombres)=='C13_imag')[0][0]\n",
    "\n",
    "      c13real =  img_test_arr[c13real_band_num, :,:] \n",
    "      c13imag =  img_test_arr[c13imag_band_num, :,:] \n",
    "      # Modificado 10.06.2022\n",
    "      np.seterr(divide='ignore', invalid='ignore')\n",
    "      c13imag = c13imag.astype('float')\n",
    "      d_calculated['CPD'] = np.degrees(np.arctan(c13real/c13imag))\n",
    "\n",
    "    for b in [x for x in range(n_bandas) if x != incidence_angle_band]:\n",
    "      banda_nombre = bandas_nombres[b]\n",
    "      if banda_nombre!='HV2' and banda_nombre!='C13_real' and banda_nombre!='C13_imag':\n",
    "        mean = means[b]\n",
    "        std = stds[b]\n",
    "      elif banda_nombre == 'HV2':\n",
    "        mean = np.mean(d_calculated['HV'][mask[:,:]])\n",
    "        std = np.std(d_calculated['HV'][mask[:,:]])\n",
    "        banda_nombre = 'HV'\n",
    "        #print(banda_nombre, mean, std)\n",
    "      elif banda_nombre == 'C13_real':\n",
    "        mean = np.mean(d_calculated['CPD'][mask[:,:]])\n",
    "        std = np.std(d_calculated['CPD'][mask[:,:]])\n",
    "        banda_nombre = 'CPD'\n",
    "        #print(banda_nombre, mean, std)\n",
    "\n",
    "      if mean!=0 and std!=0 and banda_nombre!='C13_imag' and ~np.isnan(mean) and ~np.isnan(std):# aca camboar para que sean ~(mean==0 and std==0)\n",
    "        #print(banda_nombre)\n",
    "        #d_aux[b] = {'id':int(i), 'banda_num':b, 'banda_nombre':banda_nombre,'valor_promedio': mean, 'valor_desvioest': std, 'angulo_incidencia':incidence_angle_mean}\n",
    "        d_aux[b] = {'id':int(i), 'banda_num':b, 'banda_nombre':banda_nombre, 'angulo_incidencia':incidence_angle_mean,'valor_promedio': mean, 'valor_desvioest': std}\n",
    "    if d_aux !={}:\n",
    "      d[i] = d_aux  \n",
    "  return d\n",
    "\n",
    "def get_csv(sensor_and_level, shp_file, dataframes_folder, sensor_name_sat, lista_de_imagenes_no_procesadas=[]):\n",
    "  bands_file = sensor_and_level + '/bands.txt'\n",
    "  imgs_list = glob.glob(sensor_and_level+'/*.tif')\n",
    "\n",
    "  level, n_bandas, bandas_nombres = get_bands_information(bands_file)\n",
    "\n",
    "  for img_complete in imgs_list:\n",
    "\n",
    "    print('---------------------------------------')\n",
    "    print('Corriendo: ', img_complete)\n",
    "\n",
    "    saocom_dates_xmet = None\n",
    "    if sensor_name_sat == 'SAOCOM':\n",
    "      xemt_files = glob.glob('/media/nmorandeira/T7/ExtraccionSAR/SAOCOM_shifted/Raster/SAR/SAOCOM/SAOCOM_StripMap_QP/xemt/*xemt')\n",
    "      #saocom_dates_xmet = [i for i in xemt_files if i.find(img_complete[img_complete.find('S1'): img_complete.find('_mat')])!=-1][0]\n",
    "      saocom_dates_xmet = [i for i in xemt_files if i.find(img_complete[img_complete.find('S1'): img_complete.find('S1')+48])!=-1][0]\n",
    "\n",
    "\n",
    "    # Verifico que el txt y la imagen sean congruentes:\n",
    "    img_bandas = gdal.Open(img_complete).ReadAsArray().shape[0]\n",
    "    if n_bandas != img_bandas:\n",
    "      #loggin. ----- pasar lo siguiente a log y break/continue\n",
    "      print('Las bandas del txt y de la imagen'+img_complete+' no coinciden.')\n",
    "      lista_de_imagenes_no_procesadas.append(img_complete)\n",
    "      continue\n",
    "    else:\n",
    "      # values = get_mean_std_values_from_img_v2(img, shp_file, n_bandas)\n",
    "      # print(img_complete, shp_file, n_bandas, bandas_nombres)\n",
    "      values = get_mean_std_values_from_img(img_complete, shp_file, n_bandas, bandas_nombres)\n",
    "      for v in values.keys():\n",
    "        df_aux = pd.DataFrame(values[v]).T\n",
    "        df_aux = df_aux[['id','banda_num','banda_nombre', 'angulo_incidencia','valor_promedio', 'valor_desvioest']]\n",
    "        df_aux['fecha'] = get_date(img_complete,sensor_name_sat, saocom_dates_xmet = saocom_dates_xmet)\n",
    "        #-------------------------\n",
    "        #print(d)\n",
    "        df_aux = add_table_values_to_df(d,df_aux)\n",
    "        #-----------------------------\n",
    "        df_aux['sensor'] = sensor_name_sat\n",
    "        df_aux['tipo_de_sensor'] = tipo_de_sensor\n",
    "        df_aux['level'] = level\n",
    "        df_aux['shp_file'] = shp_file\n",
    "        df_aux['img_file'] = img_complete\n",
    "        df_aux = df_aux.fillna(value='0')\n",
    "        df_aux.to_csv(dataframes_folder+sensor_name_sat+'.csv', mode='a', header=False)\n",
    "  return lista_de_imagenes_no_procesadas\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ldSv2E-oYNOm"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "# Corregir los paths de acuerdo al disco en el que se corre el script\n",
    "\n",
    "cols = ['id', 'banda_num', 'banda_nombre', 'angulo_incidencia', 'valor_promedio', 'valor_desvioest', 'fecha', 'UP','transecta',\n",
    "'geomorfo','cobertura', 'tipo_humed', 'posicion','perimetro','area','per_area','y_cen','x_cen','sensor','tipo_sensor','tipo_escena',\n",
    "'shp_file','img_file']\n",
    "\n",
    "# Direccion a la carpeta Raster:\n",
    "#folder = '/media/nmorandeira/Atlas/_PROSAT_backup20220604/Raster/'#'gdrive/MyDrive/Raster/'\n",
    "folder = '/media/nmorandeira/T7/Img_preprocesadas/Raster/'\n",
    "\n",
    "# Direccion a la carpeta donde guardaremos los dataframes:\n",
    "dataframes_folder = '/media/nmorandeira/T7/ExtraccionSAR/dataframes/'\n",
    "# Direccion a la carpeta que contiene los shapefiles\n",
    "shp_files_list = glob.glob('/media/nmorandeira/T7/ExtraccionSAR/ROIs/*shp')\n",
    "nodatavalue=-9999\n",
    "## Lista que guardara las imagenes que no fueron procesadas porque la informacion de bandas.txt no coincidia con el tif\n",
    "total_de_imagenes_no_procesadas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkkgsFPD_JyJ",
    "outputId": "8f15d8d5-1318-485b-fc75-63db84396455",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Corriendo:  /media/nmorandeira/T7/ExtraccionSAR/SAOCOM_shifted/Raster/SAR/SAOCOM/SAOCOM_StripMap_QP/decomp/S1A_OPER_SAR_EOSSP__CORE_L1A_OLF_20220421T203040_shifted_x6y-3.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: /media/nmorandeira/T7/ExtraccionSAR/SAOCOM_shifted/Raster/SAR/SAOCOM/SAOCOM_StripMap_QP/decomp/S1A_OPER_SAR_EOSSP__CORE_L1A_OLF_20220421T203040_shifted_x6y-3.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: /media/nmorandeira/T7/ExtraccionSAR/SAOCOM_shifted/Raster/SAR/SAOCOM/SAOCOM_StripMap_QP/decomp/S1A_OPER_SAR_EOSSP__CORE_L1A_OLF_20220421T203040_shifted_x6y-3.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
     ]
    }
   ],
   "source": [
    "# Comienza el cálculo\n",
    "# Obtiene las subfolders de Raster, en este caso la direccion a la carpea SAR\n",
    "subfolders = [ f.path for f in os.scandir(folder) if f.is_dir() ]\n",
    "\n",
    "for s in subfolders:\n",
    "  tipo_de_sensor =  os.path.basename(os.path.normpath(s)).upper()\n",
    "  #sensorsfolders = [ f.path for f in os.scandir(s) if f.is_dir()]\n",
    "  sensorsfolders = ['/media/nmorandeira/T7/ExtraccionSAR/SAOCOM_shifted/Raster/SAR/SAOCOM']\n",
    "  #sensorsfolders = ['/media/nmorandeira/T7/Img_preprocesadas/Raster/SAR/ALOS']\n",
    "  #sensorsfolders = ['/media/nmorandeira/Atlas/_PROSAT_backup20220604/Raster/SAR/SENTINEL']\n",
    "\n",
    "  for sensor in sensorsfolders:\n",
    "    sensor_name_sat =  os.path.basename(os.path.normpath(sensor)).upper()\n",
    "    sensorandlevelfolders = [ f.path for f in os.scandir(sensor) if f.is_dir()]\n",
    "\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.to_csv(dataframes_folder+sensor_name_sat+'.csv')\n",
    "\n",
    "    for shp_file in shp_files_list:\n",
    "      d = vector_table_to_dic(shp_file)\n",
    "      #sensorandlevelfolders = ['/media/nmorandeira/Atlas/_PROSAT_backup20220604/Raster/SAR/SAOCOM/SAOCOM_StripMap_QP']\n",
    "      for sensor_and_level in sensorandlevelfolders:\n",
    "        # SAOCOM tiene mas carpetas: polarizaciones y descomposiciones\n",
    "        if sensor_name_sat == 'SAOCOM':\n",
    "          for fold in [ f.path for f in os.scandir(sensor_and_level) if f.is_dir()]:\n",
    "            lista_de_imagenes_no_procesadas = get_csv(fold, shp_file, dataframes_folder, sensor_name_sat)\n",
    "            total_de_imagenes_no_procesadas.append(lista_de_imagenes_no_procesadas)\n",
    "        else:\n",
    "          lista_de_imagenes_no_procesadas = get_csv(sensor_and_level, shp_file, dataframes_folder, sensor_name_sat)\n",
    "          total_de_imagenes_no_procesadas.append(lista_de_imagenes_no_procesadas)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3_creación_de_DataFrames_emprolijando.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
